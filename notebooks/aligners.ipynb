{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not \"../src\" in sys.path:\n",
    "    sys.path.append(\"../src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('../data/test.csv'), PosixPath('../data/train.csv')]\n"
     ]
    }
   ],
   "source": [
    "INPUTDIR = Path(\"..\")/\"data\"\n",
    "print(list(INPUTDIR.iterdir()))\n",
    "train_df = pd.read_csv(INPUTDIR / \"train.csv\")\n",
    "test_df = pd.read_csv(INPUTDIR / \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1875, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import remove_cap, align, word_regex\n",
    "import re\n",
    "word_regex2 = re.compile(\"(\\W+)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('τῆς ἡδεῖας πλεονεξίας πολλοὺς εἰς τὴν τῶν ἀλλ',\n",
       " 'της ἐδίας πλσον ἐξιας πολλους ἐις τὴν τῶν ἀλ')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht, st = train_df[\"HUMAN_TRANSCRIPTION SYSTEM_TRANSCRIPTION\".split()].values[3]\n",
    "ht, st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import unicodedata\n",
    "# def _remove_cap(char):\n",
    "#     return unicodedata.normalize(\"NFC\", unicodedata.normalize(\"NFD\", char)[:1])\n",
    "# def remove_cap(s):\n",
    "#     return \"\".join([_remove_cap(char) for char in s])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {('΄', 'GREEK TONOS'): 2,\n",
       "             ('᾽', 'GREEK KORONIS'): 388,\n",
       "             (';', 'GREEK QUESTION MARK'): 17,\n",
       "             ('·', 'GREEK ANO TELEIA'): 67,\n",
       "             ('᾿', 'GREEK PSILI'): 14})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "from collections import defaultdict\n",
    "symbols = defaultdict(int)\n",
    "for ht, mt in train_df[\"HUMAN_TRANSCRIPTION SYSTEM_TRANSCRIPTION\".split()].values:\n",
    "    spaces = [w.strip() for w in word_regex2.split(ht) if word_regex.match(w)]\n",
    "    spaces = [s for s in spaces if len(s) > 0]\n",
    "    if len(spaces) < 1:\n",
    "        continue\n",
    "    for w in spaces:\n",
    "        for ch in w:\n",
    "            name = unicodedata.name(ch)\n",
    "            if name.find(\"GREEK\") >= 0:\n",
    "                symbols[(ch, name)] += 1\n",
    "    #break\n",
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'TONOS': 3232, 'PSILI': 2250, 'PERISPOMENI': 1754, 'VARIA': 1668, 'DASIA': 843, 'OXIA': 712, 'YPOGEGRAMMENI': 352, 'DIALYTIKA': 13})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({'PSILI': 1291,\n",
       "         'PERISPOMENI': 895,\n",
       "         'VARIA': 1034,\n",
       "         'TONOS': 1931,\n",
       "         'DASIA': 408,\n",
       "         'OXIA': 133,\n",
       "         'YPOGEGRAMMENI': 128})"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "def letters_with(texts, symbol=\"PSILI\"):\n",
    "    for line in texts:\n",
    "        for i, char in enumerate(line):\n",
    "            char = char.lower()\n",
    "            name = unicodedata.name(char)\n",
    "            if name.find(symbol) >= 0:\n",
    "                letters = unicodedata.normalize(\"NFD\", char)[:1]\n",
    "                letters = unicodedata.normalize(\"NFC\", letters)\n",
    "                yield letters\n",
    "\n",
    "and_regex = re.compile(\"\\s+AND\\s+\")\n",
    "def letters_with2(texts, symbol=\"PSILI\"):\n",
    "    for line in texts:\n",
    "        for i, char in enumerate(line):\n",
    "            name = unicodedata.name(char)\n",
    "            if name.find(\"WITH\") >= 0:\n",
    "                # letters = unicodedata.normalize(\"NFD\", char)[1:]\n",
    "                # letters = unicodedata.normalize(\"NFC\", letters)\n",
    "                k = name.find(\"WITH\")\n",
    "                name = name[k+5:]\n",
    "                for accent in and_regex.split(name):\n",
    "                    yield accent\n",
    "\n",
    "\n",
    "\n",
    "print(Counter(list(letters_with2(train_df.HUMAN_TRANSCRIPTION.values))))\n",
    "Counter(list(letters_with2(train_df.SYSTEM_TRANSCRIPTION.values)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Symbol PSILI\n",
      "Counter({'ε': 726, 'α': 575, 'υ': 364, 'ι': 347, 'η': 101, 'ω': 68, 'ο': 58, '᾿': 14, 'ρ': 11})\n",
      "\n",
      "Counter({'α': 398, 'υ': 394, 'ε': 369, 'ι': 89, 'η': 31, 'ω': 10})\n",
      "---\n",
      "Symbol TONOS\n",
      "Counter({'ι': 791, 'ο': 596, 'α': 567, 'ε': 555, 'υ': 310, 'η': 264, 'ω': 149, '΄': 2})\n",
      "\n",
      "Counter({'ι': 622, 'ο': 488, 'η': 248, 'α': 227, 'ε': 165, 'υ': 128, 'ω': 53})\n",
      "---\n",
      "Symbol VARIA\n",
      "Counter({'ι': 477, 'α': 307, 'η': 281, 'ο': 262, 'ε': 174, 'υ': 119, 'ω': 48})\n",
      "\n",
      "Counter({'ι': 308, 'η': 229, 'ο': 228, 'ε': 125, 'υ': 56, 'α': 51, 'ω': 37})\n",
      "---\n",
      "Symbol PERISPOMENI\n",
      "Counter({'ω': 518, 'υ': 437, 'ι': 423, 'η': 313, 'α': 63})\n",
      "\n",
      "Counter({'ω': 408, 'υ': 199, 'ι': 149, 'η': 139})\n",
      "---\n",
      "Symbol DASIA\n",
      "Counter({'ο': 202, 'υ': 159, 'η': 152, 'ω': 101, 'ι': 91, 'ε': 52, 'α': 50, 'ρ': 36})\n",
      "\n",
      "Counter({'ο': 156, 'υ': 89, 'η': 63, 'ω': 38, 'ι': 23, 'ε': 21, 'α': 18})\n",
      "---\n",
      "Symbol OXIA\n",
      "Counter({'ε': 186, 'α': 124, 'ι': 116, 'ο': 111, 'υ': 75, 'η': 64, 'ω': 36})\n",
      "\n",
      "Counter({'ε': 37, 'ω': 35, 'ι': 28, 'ο': 27, 'η': 6})\n",
      "---\n",
      "Symbol YPOGEGRAMMENI\n",
      "Counter({'ω': 182, 'η': 117, 'α': 53})\n",
      "\n",
      "Counter({'ω': 126, 'η': 1, 'α': 1})\n",
      "---\n",
      "Symbol DIALYTIKA\n",
      "Counter({'ι': 13})\n",
      "\n",
      "Counter()\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "for symbol in [\n",
    "        \"PSILI\", \"TONOS\", \n",
    "        \"VARIA\", \"PERISPOMENI\", \"DASIA\", \"OXIA\", \"YPOGEGRAMMENI\",\n",
    "        \"DIALYTIKA\"\n",
    "        ]:\n",
    "    print(\"Symbol\", symbol)\n",
    "    count_symb = Counter(list(\n",
    "        letters_with(\n",
    "            train_df.HUMAN_TRANSCRIPTION.values,\n",
    "            symbol=symbol\n",
    "        )))\n",
    "    print(count_symb)\n",
    "    print()\n",
    "    count_symb = Counter(list(\n",
    "        letters_with(\n",
    "            train_df.SYSTEM_TRANSCRIPTION.values,\n",
    "            symbol=symbol\n",
    "        )))\n",
    "    print(count_symb)\n",
    "    print(\"---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ht: ['αβ', 'αγ', 'αι', 'αλ', 'αμ', 'αν', 'αρ', 'ας', 'αυ', 'αφ', 'βα', 'βη', 'βο', 'βω', 'γα', 'γε', 'γη', 'γι', 'γυ', 'γω', 'δε', 'δη', 'δι', 'δυ', 'δω', 'εδ', 'εθ', 'ει', 'εκ', 'ελ', 'εν', 'εξ', 'επ', 'ερ', 'ες', 'ετ', 'ευ', 'εφ', 'ζη', 'ηδ', 'ηλ', 'ην', 'ης', 'θα', 'θε', 'θν', 'θς', 'θυ', 'θω', 'ιε', 'ιθ', 'ιν', 'ις', 'ιω', 'κα', 'κε', 'κη', 'κν', 'κο', 'κς', 'κυ', 'κω', 'λα', 'λε', 'λη', 'λω', 'μα', 'με', 'μη', 'μο', 'μω', 'να', 'νη', 'νι', 'νυ', 'νω', 'οδ', 'οι', 'ολ', 'ον', 'ορ', 'ος', 'οτ', 'ου', 'πα', 'πε', 'πι', 'πο', 'ρα', 'ρε', 'ρη', 'ρι', 'σα', 'σε', 'ση', 'σι', 'συ', 'σω', 'τα', 'τε', 'τη', 'τι', 'το', 'τω', 'υμ', 'υπ', 'φα', 'φο', 'φυ', 'χε', 'χν', 'χς', 'χυ', 'χω', 'ψε', 'ψυ', 'ωδ', 'ων', 'ως']\n",
      "\n",
      "mt: ['αα', 'αδ', 'αε', 'αη', 'αι', 'ακ', 'αλ', 'αν', 'αο', 'αρ', 'ας', 'ατ', 'αυ', 'αω', 'βα', 'βε', 'βη', 'βο', 'γα', 'γε', 'γη', 'γι', 'γν', 'γρ', 'γω', 'δα', 'δε', 'δη', 'δι', 'δκ', 'δν', 'δρ', 'δς', 'δσ', 'δυ', 'δω', 'εα', 'εγ', 'εε', 'εη', 'ει', 'εκ', 'ελ', 'εμ', 'εν', 'εξ', 'εο', 'επ', 'ερ', 'ες', 'εσ', 'ευ', 'εχ', 'ζη', 'ζν', 'ζω', 'ημ', 'ην', 'ηρ', 'ης', 'ητ', 'θα', 'θε', 'θη', 'θι', 'θν', 'θο', 'θς', 'θυ', 'θω', 'ια', 'ιε', 'ιη', 'ιμ', 'ιν', 'ιο', 'ις', 'ιφ', 'ιω', 'κα', 'κγ', 'κε', 'κη', 'κι', 'κν', 'κς', 'κυ', 'κω', 'λα', 'λη', 'λλ', 'λω', 'μα', 'με', 'μη', 'μι', 'μτ', 'μυ', 'μω', 'να', 'νη', 'νι', 'νν', 'νο', 'νω', 'ξα', 'ξη', 'ξι', 'ξυ', 'ξω', 'οα', 'οδ', 'οε', 'οη', 'οι', 'οκ', 'ολ', 'ομ', 'ον', 'οο', 'οπ', 'ορ', 'ος', 'οσ', 'οτ', 'ου', 'οω', 'πα', 'πε', 'πη', 'πι', 'πλ', 'πν', 'πο', 'πρ', 'πφ', 'πω', 'ρα', 'ρι', 'ρν', 'ςκ', 'ςο', 'σα', 'σε', 'σι', 'σκ', 'σν', 'σο', 'σς', 'στ', 'συ', 'σω', 'τα', 'τε', 'τη', 'τι', 'τκ', 'τλ', 'τν', 'τξ', 'το', 'τρ', 'τς', 'τυ', 'τω', 'υρ', 'φη', 'φι', 'φυ', 'χη', 'χν', 'χρ', 'χς', 'χυ', 'χω', 'ψγ', 'ψη', 'ων', 'ωρ', 'ως', 'ωσ']\n",
      "\n",
      "[('αα', 1), ('αδ', 1), ('αε', 2), ('αη', 1), ('ακ', 2), ('αο', 2), ('ατ', 1), ('αω', 2), ('βε', 1), ('γν', 3), ('γρ', 1), ('δα', 5), ('δκ', 1), ('δν', 3), ('δρ', 2), ('δς', 2), ('δσ', 1), ('εα', 6), ('εγ', 1), ('εε', 3), ('εη', 4), ('εμ', 1), ('εο', 1), ('εσ', 1), ('εχ', 1), ('ζν', 1), ('ζω', 2), ('ημ', 2), ('ηρ', 3), ('ητ', 1), ('θη', 4), ('θι', 1), ('θο', 1), ('ια', 4), ('ιη', 2), ('ιμ', 1), ('ιο', 2), ('ιφ', 1), ('κγ', 1), ('κι', 15), ('λλ', 1), ('μι', 5), ('μτ', 1), ('μυ', 2), ('νν', 3), ('νο', 1), ('ξα', 3), ('ξη', 1), ('ξι', 2), ('ξυ', 2), ('ξω', 1), ('οα', 3), ('οε', 3), ('οη', 2), ('οκ', 2), ('ομ', 1), ('οο', 4), ('οπ', 1), ('οσ', 1), ('οω', 1), ('πη', 1), ('πλ', 2), ('πν', 5), ('πρ', 10), ('πφ', 1), ('πω', 2), ('ρν', 1), ('ςκ', 1), ('ςο', 1), ('σκ', 1), ('σν', 1), ('σο', 2), ('σς', 1), ('στ', 1), ('τκ', 2), ('τλ', 1), ('τν', 12), ('τξ', 1), ('τρ', 7), ('τς', 1), ('τυ', 4), ('υρ', 2), ('φη', 4), ('φι', 2), ('χη', 1), ('χρ', 1), ('ψγ', 1), ('ψη', 1), ('ωρ', 1), ('ωσ', 1)]\n"
     ]
    }
   ],
   "source": [
    "ht_train = train_df.HUMAN_TRANSCRIPTION.apply(lambda x: word_regex.split(x)).values\n",
    "\n",
    "mt_train = train_df.SYSTEM_TRANSCRIPTION.apply(lambda x: word_regex.split(x)).values\n",
    "\n",
    "def print_wc(texts, l=1):\n",
    "    words_counter = Counter([remove_cap(w.lower()) for line in texts for w in line])\n",
    "    d = {w: words_counter[w] for w in words_counter if len(w) == l}\n",
    "    return d\n",
    "\n",
    "ht_words = (print_wc(ht_train, 2))\n",
    "print(\"ht:\", sorted(ht_words))\n",
    "print()\n",
    "mt_words = (print_wc(mt_train, 2))\n",
    "print(\"mt:\", sorted(mt_words))\n",
    "# β ζ λ π ς\n",
    "print()\n",
    "print(sorted([(m, mt_words[m]) for m in mt_words if m not in ht_words]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['τῆς', 'ἡδεῖας', 'πλεονεξίας', 'πολλοὺς', 'εἰς', 'τὴν', 'τῶν', 'ἀλλ'] ['της', 'ἐδίας', 'πλσον', 'ἐξιας', 'πολλους', 'ἐις', 'τὴν', 'τῶν', 'ἀλ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('τῆς', 'της', True),\n",
       " (None, 'ἐδίας', False),\n",
       " (None, 'πλσον', False),\n",
       " (None, 'ἐξιας', False),\n",
       " ('ἡδεῖας', None, False),\n",
       " ('πλεονεξίας', None, False),\n",
       " ('πολλοὺς', 'πολλους', True),\n",
       " ('εἰς', 'ἐις', True),\n",
       " ('τὴν', 'τὴν', True),\n",
       " ('τῶν', 'τῶν', True),\n",
       " (None, 'ἀλ', False),\n",
       " ('ἀλλ', None, False)]"
      ]
     },
     "execution_count": 1685,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "a, b = word_regex.split(ht), word_regex.split(st)\n",
    "a_, b_ = [remove_cap(aword) for aword in a], [remove_cap(bword) for bword in b]\n",
    "print(a, b)\n",
    "result = align(a_, b_)\n",
    "result.do_backtracing(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# rx.split(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'της ηδειας πλεονεξιας πολλους εις την των αλλ'"
      ]
     },
     "execution_count": 1687,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_cap(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e175968380534dd28bcc4db40769bad2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_results = []\n",
    "\n",
    "for ht, st in tqdm(train_df[\"HUMAN_TRANSCRIPTION SYSTEM_TRANSCRIPTION\".split()].values):\n",
    "    a, b = word_regex.split(ht), word_regex.split(st)\n",
    "    a_, b_ = [remove_cap(aword) for aword in a], [remove_cap(bword) for bword in b]\n",
    "    result = align(a_, b_)\n",
    "    bt_result = result.do_backtracing(a, b)\n",
    "    all_results.append(bt_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a3f24ab88ba45019ae1d1e5a3502f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "matches_marks = defaultdict(list)\n",
    "for sample in tqdm(all_results):\n",
    "    for ht_word, st_word, is_match in sample:\n",
    "        if is_match and ht_word != st_word:\n",
    "            matches_marks[ht_word].append(st_word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "matches_marks_grouped = {k: Counter(v) for k, v in matches_marks.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacement_rules = {\n",
    "    stw: htw\n",
    "    for htw, stcounter in matches_marks_grouped.items()\n",
    "    for stw in stcounter\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GREEK SMALL LETTER TAU\n",
      "GREEK SMALL LETTER OMICRON\n",
      "GREEK SMALL LETTER UPSILON\n",
      "COMBINING GREEK PERISPOMENI\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "for x in unicodedata.normalize(\"NFD\", replacement_rules[\"του\"]):\n",
    "    print(unicodedata.name(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ἐγγινομένα πάθη μὴ σβεννύντες ἀλλὰ τῆ εκλύσει',\n",
       "       'τοῦ βίου τοῦ καθ ΄ εαυτοὺς πολλὰ γίνεσθαι συγχωροῦν',\n",
       "       'τες ἐμπυρίζουσι τὸν ἀμπελῶνα ἀλλὰ καὶ ὁ διὰ', ...,\n",
       "       'τα ανινα υπεμεινεν οπου γε και τον στρον κατε',\n",
       "       'δεξατο ινα ημας τους υπο αμαρτιων προδε',\n",
       "       'δομενους της καταρας ελευθερωση και βοα'], dtype=object)"
      ]
     },
     "execution_count": 1694,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "train_df.HUMAN_TRANSCRIPTION.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67c3c59cea774be2ac27c447cf8e86e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def collect_mismatch(pairs):\n",
    "    a, b = list(zip(*pairs))\n",
    "    a = [x for x in a if x is not None]\n",
    "    b = [x for x in b if x is not None]\n",
    "    return a, b\n",
    "\n",
    "mm_pairs = []\n",
    "for line in tqdm(all_results):\n",
    "    pair = []\n",
    "    for a, b, is_match in line:\n",
    "        if is_match:\n",
    "            if len(pair) > 0:\n",
    "                mm_pairs.append(collect_mismatch(pair))\n",
    "                pair = []\n",
    "            continue\n",
    "        pair.append((a, b))\n",
    "    if len(pair) > 0:\n",
    "        mm_pairs.append(collect_mismatch(pair))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = mm_pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1697,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['βίου'], ['β', 'ου'])"
      ]
     },
     "execution_count": 1697,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['βίου'] ['β', 'ου']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(None, 'β', False), (None, 'ου', False), ('βιου', None, False)]"
      ]
     },
     "execution_count": 1698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_, b_ = [remove_cap(aword) for aword in a], [remove_cap(bword) for bword in b]\n",
    "print(a, b)\n",
    "result = align(a_, b_)\n",
    "result.do_backtracing(a_, b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1699,
   "metadata": {},
   "outputs": [],
   "source": [
    "hstats = []\n",
    "mstats = []\n",
    "\n",
    "for ht, mt in mm_pairs:\n",
    "    hstats.append(len(ht))\n",
    "    mstats.append(len(mt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1700,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.0, 6.0)"
      ]
     },
     "execution_count": 1700,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.percentile(hstats, 95), np.percentile(mstats, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = train_df.SYSTEM_TRANSCRIPTION.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1702,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.el.examples import sentences \n",
    "\n",
    "nlp = spacy.load(\"el_core_news_sm\")\n",
    "#doc = nlp(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1703,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ἐγγενομεναπαδημησμεννωτες ADJ amod\n",
      "ἀλλατῆε NOUN obj\n",
      "κλησει VERB ROOT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.text, token.pos_, token.dep_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CharToken(char='h', bow=True, eow=False),\n",
       " CharToken(char='e', bow=False, eow=False),\n",
       " CharToken(char='l', bow=False, eow=False),\n",
       " CharToken(char='l', bow=False, eow=False),\n",
       " CharToken(char='o', bow=False, eow=True)]"
      ]
     },
     "execution_count": 1705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "from datastruct import align_spaces\n",
    "from datastruct import word2tokens\n",
    "    \n",
    "word2tokens(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1706,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4]\n",
      "['βίου'] ['β', 'ου']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('β', 'β', True), ('ι', None, False), ('ο', 'ο', True), ('υ', 'υ', True)]"
      ]
     },
     "execution_count": 1706,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alengths = [len(x) for x in a]\n",
    "print(alengths)\n",
    "ajoined = \"\".join(a)\n",
    "bjoined = \"\".join(b)\n",
    "a_, b_ = [remove_cap(aword) for aword in ajoined], [remove_cap(bword) for bword in bjoined]\n",
    "print(a, b)\n",
    "result = align(a_, b_)\n",
    "result.do_backtracing(a_, b_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1707,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(CharToken(char='β', bow=True, eow=False),\n",
       "  CharToken(char='β', bow=True, eow=True),\n",
       "  True),\n",
       " (CharToken(char='ι', bow=False, eow=False), None, False),\n",
       " (CharToken(char='ο', bow=False, eow=False),\n",
       "  CharToken(char='ο', bow=True, eow=False),\n",
       "  True),\n",
       " (CharToken(char='υ', bow=False, eow=True),\n",
       "  CharToken(char='υ', bow=False, eow=True),\n",
       "  True)]"
      ]
     },
     "execution_count": 1707,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_, b_ = [remove_cap(aword) for aword in a], [remove_cap(bword) for bword in b]\n",
    "\n",
    "aa = [t for w in a_ for t in word2tokens(w)]\n",
    "bb = [t for w in b_ for t in word2tokens(w)]\n",
    "\n",
    "\n",
    "result = align(aa, bb)\n",
    "result.do_backtracing(aa, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1708,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result[2][16, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1709,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokens2words(tokens):\n",
    "\n",
    "#split_by_word(tokens1, tokens2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1710,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7278fa760cd04764a05546a7b8b79dc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3067 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corrected_pairs = []\n",
    "#do_break=False\n",
    "for ht, mt in tqdm(mm_pairs):\n",
    "    a_, b_ = [remove_cap(aword) for aword in ht], [remove_cap(bword) for bword in mt]\n",
    "\n",
    "    aa = [t for w in a_ for t in word2tokens(w)]\n",
    "    bb = [t for w in b_ for t in word2tokens(w)]\n",
    "    # print(aa, bb)\n",
    "\n",
    "    result = align(aa, bb)\n",
    "    alignment = result.do_backtracing(aa, bb)\n",
    "    if len(alignment) == 0:\n",
    "        continue\n",
    "    #t1_ = [x[0] for x in alignment]\n",
    "    #t2_ = [x[1] for x in alignment]\n",
    "    #m = [x[2] for x in alignment]\n",
    "    t1_, t2_, m = list(zip(*alignment))\n",
    "    for words in split_by_word(t1_, t2_):\n",
    "        \n",
    "        t1, t2 = list(zip(*words))\n",
    "        corrected_pairs.append((tokens2words(t1), tokens2words(t2)))\n",
    "        #do_break =True\n",
    "    #if do_break:\n",
    "    #    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ελευθερωση', 'και', 'βοα']"
      ]
     },
     "execution_count": 1711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(alignment), len(t1_), len(t2_), len(m)\n",
    "# split_by_word(t1_, t2_, verbose=True)\n",
    "#alignment\n",
    "tokens2words(t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_len, mt_len = list(zip(*[(len(x), len(y)) for x, y in corrected_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7, 1.0, 1.0, 4.0, 4.0)"
      ]
     },
     "execution_count": 1713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(ht_len), np.max(mt_len), np.median(ht_len), np.median(ht_len), np.percentile(ht_len, 95), np.percentile(ht_len, 95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "metadata": {},
   "outputs": [],
   "source": [
    "ht_sum, mt_sum = list(zip(*[(sum([len(x)for x in xs]), sum([len(y)for y in ys])) for xs, ys in corrected_pairs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1715,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47 43\n",
      "7.0 7.0\n",
      "18.0 17.0\n"
     ]
    }
   ],
   "source": [
    "for func in [np.max, np.median, lambda x: np.percentile(x, 95)]:\n",
    "    print(func(ht_sum), func(mt_sum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4bd0441d0924d7aa3ccf15874ff50c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datastruct import BasicVocab\n",
    "    \n",
    "vocab = BasicVocab()\n",
    "for line in tqdm(train_df.HUMAN_TRANSCRIPTION.values):\n",
    "    words = word_regex.split(line)\n",
    "    words_ = [remove_cap(word) for word in words]\n",
    "    vocab.add_sentence(words)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 1717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size = 2\n",
    "np.arange(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([('ἐγγινομένα',),\n",
       "  ('πάθη',),\n",
       "  ('μὴ',),\n",
       "  ('σβεννύντες',),\n",
       "  ('ἀλλὰ',),\n",
       "  ('τῆ',),\n",
       "  ('εκλύσει',)],\n",
       " ['ἐγγινομένα', 'πάθη', 'μὴ', 'σβεννύντες', 'ἀλλὰ', 'τῆ', 'εκλύσει'])"
      ]
     },
     "execution_count": 1718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from common import sliding_window\n",
    "\n",
    "list(sliding_window(words, 1)), words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1719,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ἐγγινομένα',)\n"
     ]
    }
   ],
   "source": [
    "for n in range(1, 4):\n",
    "    for word_seq in sliding_window(words, n):\n",
    "        print(word_seq)\n",
    "        break\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('ἐγγινομένα',)"
      ]
     },
     "execution_count": 1720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: <datastruct.AdvancedVocab object at 0x7faa2f1f2e10>, 2: <datastruct.AdvancedVocab object at 0x7faa2f1f20d0>, 3: <datastruct.AdvancedVocab object at 0x7faa2f1f29d0>, 4: <datastruct.AdvancedVocab object at 0x7faa2f1f28d0>}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b6daf50b214c529cdac7eb2dab06e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1875 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datastruct import AdvancedVocab\n",
    "vocabs = {\n",
    "    n: AdvancedVocab()\n",
    "    for n in np.arange(4)+1\n",
    "}\n",
    "print(vocabs)\n",
    "#\n",
    "for line in tqdm(train_df.HUMAN_TRANSCRIPTION.values):\n",
    "    words = word_regex.split(line)\n",
    "    words = [w for w in words if len(w) > 0]\n",
    "    words_ = [remove_cap(word) for word in words]\n",
    "    # vocab.add_sentence(words)\n",
    "    for n in range(1, 5):\n",
    "        # print(type(n))\n",
    "        for word_seq in sliding_window(words, n):\n",
    "\n",
    "            # print(word_seq)\n",
    "            vocabs[n].append(word_seq)\n",
    "        # pass\n",
    "\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in vocabs:\n",
    "    vocabs[n].precompute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<datastruct.AdvancedVocab at 0x7faa2f1f20d0>"
      ]
     },
     "execution_count": 1723,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabs[2].find_nearby(self, query_str, max_rad=1, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece7d912c0464b44906537c20dd201c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5511 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datastruct import Word\n",
    "distances = []\n",
    "for ht, mt in tqdm(corrected_pairs):\n",
    "    ht_word = Word(ht)\n",
    "    mt_word = Word(mt)\n",
    "    a, b = vocabs[2].bow2vector(ht_word.bow), vocabs[2].bow2vector(mt_word.bow)\n",
    "    dist = np.abs(a - b).sum()\n",
    "    d2 = np.sum([max(x, y) for x, y in zip(a, b)])\n",
    "    distances.append(dist/d2)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(['γενους', 'γεγονε', 'ανος'], ['γενθυγεγονενανος']),\n",
       " (['και', 'τι', 'λε'], ['οτιμε']),\n",
       " (['ημετεραν'], ['η', 'μετεραν']),\n",
       " (['υπεδυ', 'σαρκα'], ['υπεθσαρκα']),\n",
       " (['και', 'τ', 'αλλα', 'παν'], ['ειταλλαπαν']),\n",
       " (['υπεμεινεν'], ['υπεμειμεν']),\n",
       " (['οπου', 'γε', 'και'], ['οπουγεκαι']),\n",
       " (['τον', 'στρον'], ['ετριν']),\n",
       " (['υπο', 'αμαρτιων'], ['υποαμαρτιων']),\n",
       " (['ελευθερωση', 'και', 'βοα'], ['ελευθερωσηψβοα'])]"
      ]
     },
     "execution_count": 1726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_pairs[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum([i!= j for i, j in zip(ht_word.no_caps, mt_word.no_caps)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3623889085392239, 0.3333333333333333, 1.0)"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(distances), np.median(distances), np.percentile(distances, 95) # consider 95 percentile to be the default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1729,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mt_word.tokens_no_caps, word.tokens_no_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1730,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word.tokens_no_caps, word.no_caps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1731,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source: ['ελευθερωσηψβοα'] target: ['ελευθερωση', 'και', 'βοα']\n",
      "['ελευθερωσηψβοα'] ('ἔσθ', 'ἃ', 'βούλῃ') 5.0\n",
      "12\n",
      "aligned:\n",
      "ελ <- \n",
      "ευθ <- ἔσθ\n",
      "ερω <- \n",
      "σ <- ἃ\n",
      "ηψβοα <- βούλῃ\n",
      "['ελευθερωσηψβοα'] ('ελευθερωση', 'και', 'βοα') 4.0\n",
      "3\n",
      "aligned:\n",
      "ελευθερωση <- ελευθερωση\n",
      "ψ <- και\n",
      "βοα <- βοα\n"
     ]
    }
   ],
   "source": [
    "print(\"source:\", mt_word.sequence, \"target:\", ht_word.sequence)\n",
    "for word, dist in vocabs[3].find_nearby(mt_word.sequence, max_rad=10, verbose=False):\n",
    "    print(mt_word.sequence, word.sequence, dist)\n",
    "    result = mt_word.distance_to(word)\n",
    "    # result = align(mt_word.no_caps, word.no_caps)\n",
    "    print(result.distance)\n",
    "    alignment = result.do_backtracing(\"\".join(mt_word.sequence), word.tokens)\n",
    "    mt, rt, m = list(zip(*alignment))\n",
    "    # print(\"aligned:\", [\"\".join(word) for word in ])\n",
    "    print(\"aligned:\")\n",
    "    for word, ref in align_spaces(mt, rt):\n",
    "        print(\"\".join(word), \"<-\", \"\".join([x.char for x in ref]))\n",
    "    #for word in split_by_word(t1, t2):\n",
    "    #    print(word)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result.show_backtrace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1733,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ελευθερωσηψβοα']"
      ]
     },
     "execution_count": 1733,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_word.sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1734,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = vocabs[2].bow2vector(mt_word.bow)\n",
    "b = vocabs[2].bow2vector(ht_word.bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 1735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.abs(a-b).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1736,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input seq: ['ελευθερωση', 'και', 'βοα'], ελευθερωσηκαιβοα\n",
      "Checking index: 8808\n",
      "word_index= 8837\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[8837]"
      ]
     },
     "execution_count": 1736,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabs[3].find(['ελευθερωση', 'και', 'βοα'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1737,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 1737,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.sum([len(x) for x in ht_word.sequence]))\n",
    "np.sum([v for k, v in ht_word.bow.items()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1738,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabs[3].words[9321].sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1739,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "seqs = []\n",
    "for k in vocabs[3].nocaps2index:\n",
    "    result = align(\"ελευθερωσηκαιβο\", k)\n",
    "    results.append(result)\n",
    "    seqs.append(k)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1740,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results[0].distance, results[1].distance, results[9073].distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1741,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k = 9073\n",
    "#results[k].do_backtracing(\"ελευθερωσηκαιβο\", seqs[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1742,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8808"
      ]
     },
     "execution_count": 1742,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax([r.distance for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1743,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from space_fixer import \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1744,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8029d721dd724dbda591a4fc04ce4d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(['δικον', 'κτῆσιν', 'και', 'ἀπὸ', 'ἀρπαγῆς', 'καὶ', 'βίας', 'συλλεγόντες'],\n",
       " ['ικον', 'κτῆσιν', 'αποαρπαγης', 'καιβωας', 'συγεγοντεσ'])"
      ]
     },
     "execution_count": 1744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ht_line, mt_line in tqdm(train_df[[\"HUMAN_TRANSCRIPTION\", \"SYSTEM_TRANSCRIPTION\"]].values[7:]):\n",
    "    ht_words = word_regex.split(ht_line)\n",
    "    mt_words = word_regex.split(mt_line)\n",
    "    #words_ = [remove_cap(word) for word in words]\n",
    "    #vocab.add_sentence(words)\n",
    "    break\n",
    "ht_words, mt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1746,
   "metadata": {},
   "outputs": [],
   "source": [
    "from space_fixer import build_path_matrix\n",
    "\n",
    "dmatrix = build_path_matrix(mt_words, vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1747,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dist, closest_data = get_closest_data(mt_word, vocabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1748,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dmatrix[-1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1750,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def convert_to_line_split(dmatrix):\n",
    "from space_fixer import extract_paths\n",
    "\n",
    "\n",
    "finished_paths = extract_paths(dmatrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1751,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path 0\n",
      "0 -> 2, dist=1, 1 variants ['ικον', 'κτῆσιν']\n",
      "2 -> 4, dist=1, 1 variants ['αποαρπαγης', 'καιβωας']\n",
      "4 -> 5, dist=4, 1 variants ['συγεγοντεσ']\n",
      "Path 1\n",
      "0 -> 2, dist=1, 1 variants ['ικον', 'κτῆσιν']\n",
      "2 -> 3, dist=0, 1 variants ['αποαρπαγης']\n",
      "3 -> 4, dist=1, 1 variants ['καιβωας']\n",
      "4 -> 5, dist=4, 1 variants ['συγεγοντεσ']\n",
      "Path 2\n",
      "0 -> 1, dist=1, 5 variants ['ικον']\n",
      "1 -> 2, dist=0, 1 variants ['κτῆσιν']\n",
      "2 -> 4, dist=1, 1 variants ['αποαρπαγης', 'καιβωας']\n",
      "4 -> 5, dist=4, 1 variants ['συγεγοντεσ']\n",
      "Path 3\n",
      "0 -> 1, dist=1, 5 variants ['ικον']\n",
      "1 -> 2, dist=0, 1 variants ['κτῆσιν']\n",
      "2 -> 3, dist=0, 1 variants ['αποαρπαγης']\n",
      "3 -> 4, dist=1, 1 variants ['καιβωας']\n",
      "4 -> 5, dist=4, 1 variants ['συγεγοντεσ']\n"
     ]
    }
   ],
   "source": [
    "for i, path in enumerate(finished_paths):\n",
    "    print(f\"Path {i}\")\n",
    "    for (frag_dist, b, e, segs) in path:\n",
    "        print(f\"{b} -> {e}, dist={frag_dist}, {len(segs)} variants\", mt_words[b:e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alignment = result.do_backtracing(\"\".join(mt_word.sequence), word.tokens)\n",
    "# mt, rt, m = list(zip(*alignment))\n",
    "# # print(\"aligned:\", [\"\".join(word) for word in ])\n",
    "# print(\"aligned:\")\n",
    "# for word, ref in align_spaces(mt, rt):\n",
    "#     print(\"\".join(word), \"<-\", \"\".join([x.char for x in ref]))\n",
    "\n",
    "from space_fixer import resplit_paths\n",
    "\n",
    "for k in resplit_paths(finished_paths, mt_words):\n",
    "    variant = \" \".join(k)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['δικον', 'κτῆσιν', 'και', 'ἀπὸ', 'ἀρπαγῆς', 'καὶ', 'βίας', 'συλλεγόντες']"
      ]
     },
     "execution_count": 1754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabs[1].index2seq[21]\n",
    "ht_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1755,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ικον', 'κτῆσιν', 'αποαρπαγης', 'καιβωας', 'συγεγοντεσ']"
      ]
     },
     "execution_count": 1755,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for r, c, w in dmatrix[9][1][0][1]:  #dmatrix[1][1][0][1]:\n",
    "#    print(w)\n",
    "mt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1757,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "414380407e0749d388420375facb753a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1868 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ικον κτῆσιν απο αρπαγης και βωας συ γεγοντε σ\n",
      "ι κον κτῆσιν απο αρπαγης και βωας συ γεγοντε σ\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(['δικον', 'κτῆσιν', 'και', 'ἀπὸ', 'ἀρπαγῆς', 'καὶ', 'βίας', 'συλλεγόντες'],\n",
       " ['ικον', 'κτῆσιν', 'αποαρπαγης', 'καιβωας', 'συγεγοντεσ'])"
      ]
     },
     "execution_count": 1757,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ht_line, mt_line in tqdm(train_df[[\"HUMAN_TRANSCRIPTION\", \"SYSTEM_TRANSCRIPTION\"]].values[7:]):\n",
    "    ht_words = word_regex.split(ht_line)\n",
    "    mt_words = word_regex.split(mt_line)\n",
    "    #words_ = [remove_cap(word) for word in words]\n",
    "    #vocab.add_sentence(words)\n",
    "    dmatrix = build_path_matrix(mt_words, vocabs)\n",
    "    finished_paths = extract_paths(dmatrix)\n",
    "    for k in resplit_paths(finished_paths, mt_words):\n",
    "        variant = \" \".join(k)\n",
    "        print(variant)\n",
    "    break\n",
    "ht_words, mt_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('data_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d632e93423067b2b9b1b8d52846f85c868da433699adad534ad2cc6673775271"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
